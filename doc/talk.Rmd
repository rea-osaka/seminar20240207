---
title: "talk"
author: "nekota"
date: "2024-02-01"
output: html_document
---


# 今日のテーマ

データ分析をするには、当然データが必要になります。

ですから、必ずそのデータを準備する作業が必要になります。

そこで、今日のテーマは「データを準備する」部分に着目します。


その分析対象となるデータですが、

じゃ、「コレを分析してください」という形で、
はじめから用意されているわけではありません。


まず、

- 何処にあるのかを探す
- それを手に入れる
- 分析できる形にする

という「準備作業」が必ず必要になります。


さて、「作業」というのは、どレくらいのイメージでしょうか？


実は意外と準備のために扱うデータは大量にあります。

どれくらい大量かといえば、通常は、手作業でやるのが嫌になるくらいです。
そして、ある一定の量を超えると、
手作業では根性があっても実質的には無理なくらいの作業になります。

そこで、今日のテーマは、

**大量のデータを効率的に処理**する方法に着目し、

その方法を具体的に紹介することにしました。


で、今回は

- 人口データ

を扱ってみました


ここで、

データ分析とデータの具体的なイメージとして、
地価公示を担当されている先生方には
馴染み深い「価格動向報告」にある
人口の推移の分析を思い浮かべてください。

人口データは、
不動産の受給動向の要因として分析される
馴染み深いデータの一つです。

人口データはどんなものを想像するでしょうか？

## 人口データ

「人口データ」とはどんなものか具体的に見てみます。

- 総人口
- 男女
- 年齢別（５歳区切り、年少、生産、老齢）
- 増減（自然、社会）
- 世帯

86地域、5年（６０ヶ月）以上のデータ

これらの項目について、年若しくは月毎に
大阪府下の各市町村について計測、若しくは、推計されその数値がまとめられています。

大阪府下の各市町村については大阪府のWebページで公開されています。

https://www.pref.osaka.lg.jp/toukei/jinkou/jinkou-xlslist.html

このページを開いて、具体的なデータを少しだけ覗いてみましょう。


## 意外と大量のデータ

大阪府のページを見ながら、ダウンロード。

まず、全部のデータをダウンロードするのが煩雑です


＜実際に開く＞

新しいデータ（月次）

古いデータ（年毎で、シートが月次）

年齢別ファイル（縦に総合、男、女）となっている

等、ファイルによって違いがあることを確認




実際のファイルの中身を少し見てみると、
年によって形式が違うことがわかります。


人口のデータを分析するためには、データがどんなかたちであるとよいのか？


例えば、大阪府全体の人口の推移を見たい場合、、、

大阪府全体の人口を月毎に横か縦に並べたい

ファイルは月毎（シート毎）なので、
各ファイルから大阪府全体のデータを取り出し、
順番に並べる必要がある。５年ならば６０行（列）。
地域全てをやろうと思うと、この作業を地域分である８６回繰り返す。

セル毎のコピーを１秒間に１回やったとしても、
多分１時間半以上、この単純作業を繰り返すことになります。

これがデータ分析にあたって、必ずしなければならないデータの準備であり、
先に言ったとおり、これらの作業は、
手作業でやるのが嫌になる（若しくは、不可能）なくらい、
**大量のデータ**を処理する必要が生じます。


この作業は、１回だけならば、頑張って準備すればよいのですが、
準備すべきデータの形というのは、分析したいものによって変わります。

つまり、同じようなデータソースであったとしても、
やってみたい分析によって準備すべきデータの形が変わります。
この時に、データの形を変えるのに時間がかかるとすると、
データの分析自体が時間がかかってしまい。
面倒な分析になってしまうことになります。

一方で、短期間でデータの準備が出来れば、
いろんな分析をすぐに出来るようになり、結果として、
そのデータから得られるものが多くなるのです。

なので、データの準備の効率化はデータ分析の効率化に繋がります。






# プログラムによる自動化

「データの準備とは」をまとめれば

- データの入手
- 入手したデータの内容確認
- データ分析しやすい形へデータを編集

全ての場面でプログラミングが役に立ちます

今日もデータ分析を得意とするR言語での例


簡単に一つづつ見ていきます


## データの入手

手作業では、クリックしていますが、

プログラムではまず、

ページの情報を取得して

それをもとにファイルをダウンロードする

という、方法が一般的。


## 入手したデータ内容の確認

先に確認したとおり、ファイルの形式はいろいろです。

それらを目視で確認するだけでなくプログラム的に確認できます。

例えば、地域の割り振りが全て同じなのか？等

その前提としてまず、エクセルファイルをRのプログラム内に読み込む必要がありますが、
Rではコレを簡単に行うことが出来るパッケージがあります。

- データファイルをRのデータとして読み込む
- データの構造を把握
- どのように編集するかを決める


## データ分析しやすい形へデータを編集

- データをRのプログラムで編集
- データをエクセル等のファイルとして出力

Rプログラム内で編集し、
最終的にRユーザーでない人でも使うことが出来るエクセルファイルとして出力します。

Rのデータをエクセルのファイルとして出力させることもRでは簡単に出来ます。


## 具体的な成果

https://github.com/rea-osaka/seminar20240207


今日のセミナーで話している、
「データの準備」に関する一つの成果として、
大阪府で配布されている人口データを
自動収集して、
分析しやすい一つの形として取りまとめたものを出力するためのプログラム例を
作成しました。

＜実際にアクセスしてディレクトリを説明＞

しかし、今日はこれのこまかな話をするのではなく、
データ準備の中でよく利用されるプログラムの技術についての話をします。

プログラムってこんなことができるんだ！という興味を
もっともらえたら良いなと思っています。



# データを入手する技術

まずは、データを入手する時点の技術に関して話です。

大まかに２つの方法があります。

- API(Application Programming Interface)
- ページの構造を読み解くスクレイピング

ひとつは、データを直接やりとりするためのサービスというものがあります。
情報を配布する側も機械化に対応した
APIという方法は、
ダイレクトにデータを得ることが出来ることが多いです。

不動産取引価格情報のAPI


もうひとつは、普通の人が見るような形式のWebから、必要な情報を取得する
htmlページの構造を読み解くスクレイピングという方法を使う。

きょうは、スクレイピングの方



## スクレイピングとは

スクレイピングとは、一般に、Webページ上の情報を機械的に取得することを言います。

有名なスクレイピングパッケージ

- https://www.crummy.com/software/BeautifulSoup/bs4/doc/
- https://rvest.tidyverse.org/

スクレイピングはあちこちで色んな形で紹介されていて情報は多い方

例えば、大阪府の人口データのページで、人口データのエクセルファイルへのリンクが沢山ありますが、このリンクが指しているURL自体を、プログラムで読み取ることが出来ます。

メジャーな高級プログラム言語、例えば、PythonやRuby、Go、そして、R言語にも、
スクレイピングを行うための関数が用意されていますので、これを利用することで比較的簡単にスクレイピングが行えます。




## スクレイピングの仕組み

スクレイピングを行うための前提知識として、
Webページが**html言語**で書かれており、
各内容がhtmlタグで構造化されている事を知っている必要があります。

例えば、htmlでのリンクは**aタグ**で、
表現され、そのhref属性にリンク先のURLが書かれています。

```{html eval=FALSE}
<html>
...
  <body>
  ...
  <a href="https://google.com" >googleのページ</a>
  ...
  <a href="https://www.yahoo.co.jp/" >Yahoo Japanのページ</a>
  ...
  </body>  
</html>
```


なので、ページの中にある全てのaタグのhrefリファレンスを調べることで、
ダウンロードしたいファイルのURLを収集することが出来るのです。




## R言語でスクレイピング

R言語の場合、[rvest](https://stringr.tidyverse.org/)パッケージにスクレイピングの関数があります。

```{r eval=FALSE, message=FALSE}
library(rvest)
library(tidyverse)

# 人口データを公開している大阪府のURL
target_url <- "https://www.pref.osaka.lg.jp/toukei/jinkou/jinkou-xlslist.html"

# ページを取得
node_data <- read_html(target_url, encoding = "shift_jis")

# 構造で選別
href_data <- 
    node_data %>% 
    html_nodes("tbody td a") %>% 
    html_attr("href")
```

- read_html()関数
- html_nodes()関数
- html_attr()関数

実際にどんなものが得られるのか見てみましょう

samplecode001





## 文字列で選別

ページ内のリンク先を全て集めると、
欲しいURL以外のURLも一緒に集まります。
この時、欲しいデータの共通項は
最後が「xlsx」となっているリンク先なので、
これだけを抜き出す必要があります。

プログラムでは一般的に、
ある規則になっている文字の並び方だけを
取り出したい時に
**「正規表現」**という表現を使って、取り出すことが出来ます。

R言語の場合、[stringr](https://stringr.tidyverse.org/)パッケージに使いやすい文字列処理の関数があります。


```{r eval=FALSE, message=FALSE}
#必要なリンクのみを取り出す
link_data <- 
    href_data %>%
    stringr::str_subset(".xlsx$") %>% 
    stringr::str_subset("5sai", negate = TRUE)

```

- str_subset()関数

## スクレイピングで得られるもの

Webページはいわゆる「文字列」で情報が表現されています。そして、ここで得られるものは、欲しいデータの在処を示したURLの文字列です。

先のR言語の例示のコードでは、
最終的に、URL文字列（そのベースの一部）のベクトル（配列）が得られます。

# データをダウンロードする

Web上のファイルをダウンロードする関数もプログラム言語には基本的に用意されています。
R言語の場合は、基本的なパッケージ(utils)の中にあるdownload.file()関数で、ファイルのダウンロードが出来ます。

```{r eval=FALSE}
# link_dataベクトルの１つめのURLをダウンロード
download.file(url = link_data[1], destfile = "datafile.xlsx")
```

この関数を使う場合、必ず、保存するファイル名を明示しなければなりません。

## 複数ファイルをダウンロードする

複数ファイルを一部エラーがあっても中断せずにダウンロードする典型の雛形のコードを紹介します。

```{r eval=FALSE}
download_by_urls <- function(urls, dest_dir = "."){

  for (i in seq_along(urls) ){
    dest_path = paste0(dest_dir, "/", basename(urls[i]))
    
    Sys.sleep(0.3)

    tryCatch({
      download.file(url = urls[i], destfile = dest_path)
    },
    error = function(e){
      message("Error!!")
      message(e)
    })
  }
}
```

実際にこのサンプルコードを走らせる場合には、保存先のディレクトリを作っておくようにしましょう。


# xlsxファイルをRに読み込む

人口データに関しては、
複数のデータファイルがあります。
これらのデータを統合するためには、データを加工して結合する必要があり、それらを行うためには、まず、**データを読み込む**必要があります。

ここで、扱うファイルはマイクロソフトのエクセルファイルのうち、xlsx拡張子が付くものです。
最近では、このエクセルファイルを様々なプログラム言語のデータとして読み込むことが出来るパッケージが開発されています。

R言語では、[openxlsx](https://ycphs.github.io/openxlsx/index.html)が有名です。

基本はエクセルファイルがある場所のパスを渡すだけで、Rのdata.frameデータとして読み込まれます。

```{r eval=FALSE}
# エクセルファイルを読み込む
df_data <- openxlsx::read.xlsx("data/data.xlsx")
```

## ファイル読み込みのサンプルコード

read.xlsx()関数に渡す引数で、エクセルファイルからどのシートを読み込むかや、行や列名をどうするか、セルのどの位置を読み込むか等を細かく指定できるので、実際に読み込むエクセルファイルのデータの配置に合わせて、プログラムで調節することが出来ます。

以下のコードは、国勢調査年のエクセルシートを読み込む際のサンプルです

```{r eval=FALSE}
# シートの指定やセルの指定をしたもの
df_data <- 
  openxlsx::read.xlsx(
    file, colNames = FALSE,
    sheet = "表9-1",
    rows = c(6:56,63:103))
```

# データの整理

省略


# データをエクセルファイルとして書き出す

読み込みと同じで[openxlsx](https://ycphs.github.io/openxlsx/index.html)パッケージにある
関数を利用します。

書き出しの関数には、data.frameを直接エクセルファイルとして書き出す方法と、
プログラム内部で、エクセルのデータを作成し、これをエクセルファイルとして書き出す方法があることを把握しておきましょう。

以下では、エクセルデータを作って、それをエクセルファイルとして出力する方法を紹介します。

## プログラムの中のエクセルデータ

エクセルファイルの構造をもった
エクセルデータをRのプログラムの中に作ってしまう。

```{r eval=FALSE}
# エクセルデータを作る
obj <- createWorkbook()

# 枚方市という名前のシートを追加
addWorksheet(obj, sheetName = "枚方市")

# 枚方市という名前のシートに人口データを追加
writeData(obj,
          sheet = "枚方市",
          x = census_data)
```

## 現実のエクセルファイルとして書き出し

プログラムの中で作ったエクセルデータを
現実のエクセルファイルとして書き出します。


```{r eval=FALSE}
# エクセルファイルとして書き出す
saveWorkbook(obj,
             file = "hirakata.xlsx",
             overwrite = TRUE)
```



## Dinner

- Eat spaghetti
- Drink wine

## Going to sleep

- Get in bed
- Count sheep


