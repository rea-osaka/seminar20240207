---
title: "talk"
author: "fukuda"
date: "2024-02-06"
output:
  pdf_document: 
    latex_engine: xelatex 
    number_sections: true
documentclass: bxjsarticle
header-includes: 
  - \usepackage{zxjatype} 
  - \usepackage[ipa]{zxjafont} 
geometry: no
---

# 今日のテーマ


「人口動態データを効率的に分析する」

なのですが、


データ分析をするには、当然、データが必要になります。

しかしそのデータは、「コレを分析してください」という形で、
はじめから用意されているわけではありません。

ですから、必ずそのデータを準備する作業が必要になります。


この準備作業は、


まず、

- 何処にあるのかを探す
- それを手に入れる
- 分析できる形にする
- （使う人に配布する）

というようなものになります。

さて、この「準備作業」というのは、
どのくらい手間が掛かりそうイメージでしょうか？

まぁ、あらためて「準備作業というものがありますよ」という話を
しているところですから、あまりピンとこないと思います。

## データが大量にある

実は意外と準備のための作業というのは煩雑で大量です。

どれくらい大量かといえば、通常は、手作業でやるのが嫌になるくらいです。
そして、ある一定の量を超えると、
手作業では根性があっても実質的には無理なくらいの作業になります。

そこで、今日のテーマは、

**大量のデータを効率的に処理**する方法に着目します。

結論から言えば、データ分析を効率化するためには、
データの準備作業の効率化は必須になります。


その方法を具体的に紹介することにしました。

また、準備作業を効率的にする必要性も説明します。


で、今回は

- 人口データ

を扱ってみました


ここで、

データ分析とデータの具体的なイメージとして、
地価公示を担当されている先生方には
馴染み深い「価格動向報告」にある
人口の推移の分析を思い浮かべてください。

人口データは、
不動産の受給動向の要因として分析される
馴染み深いデータの一つです。

実際のところ、、

コレに関する準備作業を行った成果品を提供することは、
大阪の会員にも資するとういうことで、
長尾先生から宿題を出されていました。

人口データはどんなものを想像するでしょうか？


## 人口データ

「人口データ」とはどんなものか具体的に見てみます。

- 総人口
- 男女
- 年齢別（５歳区切り、年少、生産、老齢）
- 増減（自然、社会）
- 世帯

86地域、5年（６０ヶ月）以上のデータ

これらの項目について、年若しくは月毎に
大阪府下の各市町村について計測、若しくは、推計されその数値がまとめられています。

大阪府下の各市町村については大阪府のWebページで公開されています。

https://www.pref.osaka.lg.jp/toukei/jinkou/jinkou-xlslist.html

このページを開いて、具体的なデータを少しだけ覗いてみましょう。


## 意外と大量のデータ

大阪府のページを見ながら、ダウンロード。

まず、全部のデータをダウンロードするのが煩雑です


＜実際に開く＞

新しいデータ（月次）

古いデータ（年毎で、シートが月次）

年齢別ファイル（縦に総合、男、女）となっている

等、ファイルによって違いがあることを確認




実際のファイルの中身を少し見てみると、
年によって形式が違うことがわかります。


人口のデータを分析するためには、データがどんなかたちであるとよいのか？


例えば、大阪府全体の人口の推移を見たい場合、、、

大阪府全体の人口を月毎に横か縦に並べたい

ファイルは月毎（シート毎）なので、
各ファイルから大阪府全体のデータを取り出し、
順番に並べる必要がある。５年ならば６０行（列）。
地域全てをやろうと思うと、この作業を地域分である８６回繰り返す。

セル毎のコピーを１秒間に１回やったとしても、
多分１時間半以上、この単純作業を繰り返すことになります。

これがデータ分析にあたって、必ずしなければならないデータの準備であり、
先に言ったとおり、これらの作業は、
手作業でやるのが嫌になる（若しくは、不可能）なくらい、
**大量のデータ**を処理する必要が生じます。


この作業は、１回だけならば、頑張って準備すればよいのですが、
準備すべきデータの形というのは、分析したいものによって変わります。

つまり、同じようなデータソースであったとしても、
やってみたい分析によって準備すべきデータの形が変わります。
この時に、データの形を変えるのに時間がかかるとすると、
データの分析自体が時間がかかってしまい。
面倒な分析になってしまうことになります。

一方で、短期間でデータの準備が出来れば、
いろんな分析をすぐに出来るようになり、結果として、
そのデータから得られるものが多くなるのです。

なので、データの準備の効率化はデータ分析の効率化に繋がります。






# プログラムによる自動化

「データの準備とは」をまとめれば

- データの入手
- 入手したデータの内容確認
- データ分析しやすい形へデータを編集


全ての場面でプログラミングが役に立ちます

今日もデータ分析を得意とするR言語での例


簡単に一つづつ見ていきます


## データの入手

手作業では、クリックしていますが、

プログラムではまず、

ページの情報を取得して

それをもとにファイルをダウンロードする

という、方法が一般的。


## 入手したデータ内容の確認

- データファイルをRのデータとして読み込む



コンピューターで作業するためには、
データをパソコンに読み込む必要があります。
ここでは、エクセルファイルをRのプログラム内に読み込む必要がありますが、
Rではコレを簡単に行うことが出来るパッケージがあります。

- データの構造を把握

先に確認したとおり、ファイルの形式はいろいろです。

それらを目視で確認するだけでなくプログラム的に確認できます。

例えば、地域の割り振りが全て同じなのか、
何処かに、値と異なる、列名等の文字列や説明、体裁を整える空白が無いか？等
データ配置の整合性を確認することが出来ます。


- どのように編集するかを決める

得られている現実のデータを整理して
どういう形状のデータ構造にすれば、分析が効率化されるかを検討して
ゴールのデータ形状を決めます。


## データ分析しやすい形へデータを編集

- データをRのプログラムで編集

先に決定したデータ形状になるように、
プログラムでデータを編集して、整然データを作ります。

- データをエクセル等のファイルとして出力

最終的にRユーザーでない人でも使うことが出来るエクセルファイルとして出力します。
Rのデータをエクセルのファイルとして出力させることもRでは簡単に出来ます。


## 具体的な成果

https://github.com/rea-osaka/seminar20240207


今日のセミナーで話している、
「データの準備」に関する一つの成果として、
大阪府で配布されている人口データを
自動収集して、
分析しやすい一つの形として取りまとめたものを出力するためのプログラム例を
作成しました。

＜実際にアクセスしてディレクトリを説明＞

しかし、今日はこれのこまかな話をするのではなく、
データ準備の中でよく利用されるプログラムの技術についての話をします。

プログラムってこんなことができるんだ！という興味を
もっともらえたら良いなと思っています。



# データを入手する技術

まずは、データを入手する時点の技術に関して話です。

大まかに２つの方法があります。

- API(Application Programming Interface)
- ページの構造を読み解くスクレイピング

ひとつは、データを直接やりとりするためのサービスというものがあります。
情報を配布する側も機械化に対応した
APIという方法は、
ダイレクトにデータを得ることが出来ることが多いです。

不動産取引価格情報のAPI


もうひとつは、普通の人が見るような形式のWebから、必要な情報を取得する
htmlページの構造を読み解くスクレイピングという方法を使う。

きょうは、スクレイピングの方



## スクレイピングとは

スクレイピングとは、一般に、Webページ上の情報を機械的に取得することを言います。

有名なスクレイピングパッケージ

- https://www.crummy.com/software/BeautifulSoup/bs4/doc/
- https://rvest.tidyverse.org/

スクレイピングはあちこちで色んな形で紹介されていて情報は多い方

例えば、大阪府の人口データのページで、人口データのエクセルファイルへのリンクが沢山ありますが、このリンクが指しているURL自体を、プログラムで読み取ることが出来ます。

メジャーな高級プログラム言語、例えば、PythonやRuby、Go、そして、R言語にも、
スクレイピングを行うための関数が用意されていますので、これを利用することで比較的簡単にスクレイピングが行えます。




## スクレイピングの仕組み

スクレイピングを行うための前提知識として、
Webページが**html言語**で書かれており、
各内容がhtmlタグで構造化されている事を知っている必要があります。

例えば、htmlでのリンクは**aタグ**で、
表現され、そのhref属性にリンク先のURLが書かれています。

```{html eval=FALSE}
<html>
...
  <body>
  ...
  <a href="https://google.com" >googleのページ</a>
  ...
  <a href="https://www.yahoo.co.jp/" >Yahoo Japanのページ</a>
  ...
  </body>  
</html>
```


なので、ページの中にある全てのaタグのhrefリファレンスを調べることで、
ダウンロードしたいファイルのURLを収集することが出来るのです。




## R言語でスクレイピング

R言語の場合、[rvest](https://stringr.tidyverse.org/)パッケージにスクレイピングの関数があります。

```{r eval=FALSE, message=FALSE}
library(rvest)
library(tidyverse)

# 人口データを公開している大阪府のURL
target_url <- "https://www.pref.osaka.lg.jp/toukei/jinkou/jinkou-xlslist.html"

# ページを取得
node_data <- read_html(target_url, encoding = "shift_jis")

# 構造で選別
href_data <- 
    node_data %>% 
    html_nodes("tbody td a") %>% 
    html_attr("href")
```

- read_html()関数
- html_nodes()関数
- html_attr()関数

実際にどんなものが得られるのか見てみましょう

samplecode001



## ある規則の文字列を表現する正規表現


ページ内のリンク先を全て集めると、
欲しいURL以外のURLも一緒に集まります。
この時、欲しいデータの共通項は
最後が「xlsx」となっているリンク先なので、
これだけを抜き出す必要があります。

プログラムでは一般的に、
ある規則になっている文字の並び方だけを
取り出したい時に
例えば、


- "https"で始まっている
- ".xlsx"で終わっている
- "携帯電話の番号みたいな文字列"

これら**正規表現**を利用して、文字列の選別を行えます。

実際の表記は以下のようなもの


- "^https"
- "\\.xlsx$"
- "0[89]0-[0-9]{4}-[0-9]{4}"


## 正規表現を使った文字列比較

R言語の場合、[stringr](https://stringr.tidyverse.org/)パッケージに使いやすい
文字列処理の関数があります。

- str_subset()関数

```{r eval=FALSE, message=FALSE}
library(stringr)

#必要なリンクのみを取り出す
link_data <- 
    href_data %>%
    stringr::str_subset(".xlsx$") %>% 
    stringr::str_subset("5sai", negate = TRUE)
```

実際にどのように選別されるか確認します

samplecode001


## スクレイピングで得られるもの

Webページはいわゆる「文字列」で情報が表現されています。
そして、ここで得られるものは、欲しいデータの在処を示したURLの文字列です。

先のR言語の例示のコードでは、
最終的に、URL文字列（そのベースの一部）のベクトル（配列）が得られます。



## データをダウンロードする

インターネット上のファイルをダウンロードする関数も
プログラム言語には基本的に用意されています。
R言語の場合は、基本的なパッケージ(utils)の中にあるdownload.file()関数で、
ファイルのダウンロードが出来ます。

つまり、プログラムでファイルをダウンロードできます

- download.file()関数

```{r eval=FALSE}
# ダウンロードしたいファイルのURL
target_dl_url <- "https://www.pref.osaka.lg.jp/attach/3387/00014690/jk20240101.xlsx"

# ファイルをダウンロードする
download.file(url = target_dl_url, destfile = basename(target_dl_url))
```

basename()関数をつかって、ファイル名を作成

この関数を使う場合、必ず、保存するファイル名を明示しなければなりません。




## 複数ファイルをダウンロードする

当然、プログラムでダウンロードする利点は、
自動的に複数のダウンロードを行うことです。


複数ファイルの自動ダウンロード


```{r eval=FALSE}
# ダウンロード先のURLの集合
urls <- link_data

for (i in seq_along(urls) ){
  
  #URL文字列から最後の部分をファイル名として取り出す
  dest_path = basename(urls[i])
  
  # ファイルをダウンロードする
  download.file(url = urls[i], destfile = dest_path)
}

```


実際には、完全なURLが必要なのでlink_dataを加工する必要があります。




# エクセルファイルの読み込み

プログラムで処理するには、まず、読み込みが必要

Rプログラム内では、data.frameというデータ構造で扱う

R言語では、[openxlsx](https://ycphs.github.io/openxlsx/index.html)パッケージが有名です。

人口データに関しては、
複数のデータファイルがあります。
これらのデータを統合するためには、データを加工して結合する必要があり、それらを行うためには、まず、**データを読み込む**必要があります。


```{r eval=FALSE}
library(openxlsx)

# エクセルファイルを読み込む
df_data <- read.xlsx("data/data.xlsx")
```

samplecode001.Rmd



## 細かな指示も行える

- シートの扱い
- 列目の扱い
- 読み込むセル範囲の指定

国勢調査年のファイルを読み込む際のサンプルです

censusdata_dlcode.nb.htmlにあります


```{r eval=FALSE}
# シートの指定やセルの指定をしたもの
df_data <- 
  openxlsx::read.xlsx(
    file, colNames = FALSE,
    sheet = "表9-1",
    rows = c(6:56,63:103))
```



## ファイル読み込みのサンプルコード

read.xlsx()関数に渡す引数で、エクセルファイルからどのシートを読み込むかや、行や列名をどうするか、セルのどの位置を読み込むか等を細かく指定できるので、実際に読み込むエクセルファイルのデータの配置に合わせて、プログラムで調節することが出来ます。

以下のコードは、国勢調査年のエクセルシートを読み込む際のサンプルです

```{r eval=FALSE}
# シートの指定やセルの指定をしたもの
df_data <- 
  openxlsx::read.xlsx(
    file, colNames = FALSE,
    sheet = "表9-1",
    rows = c(6:56,63:103))
```


# データの整理

data.frame構造のデータを操作する関数

|関数|機能|
|---|---|
|filter()|行を選別|
|arrange()|行を並び替え|
|select()|列を選別|
|mutate|新しい列を作成|


R言語では、[dplyr](https://dplyr.tidyverse.org/)パッケージに属しています。

通常は「[tidyverse](https://www.tidyverse.org/)」を呼び出す。


census_....htmlを見ながら実際のコード

エクセルのファイル

ファイル読み込みサブルーチン


## 複数のデータを貼り付け

複数のdata.frameデータを統合する関数

|関数|機能|
|---|---|
|rbind()|表の下に追加するイメージ|
|left_join()|表の右に追加するイメージ|


## 公開された技術書

インターネットで公開された書籍

[R for Data Science (2e)](https://r4ds.hadley.nz/)

第３章の「Data transformation」が秀逸

英語が苦手ならChatGPTでサポートしてもらう



# エクセルファイルとして出力

データの書き出しも[openxlsx](https://ycphs.github.io/openxlsx/index.html)パッケージの関数を利用

- write.xlsx()関数

```{r eval=FALSE}
library(openxlsx)

# 内蔵データirisをエクセルファイルへ書き出し
write.xlsx(iris,"hoge.xlsx")
```

これは、Rのdata.frameデータを扱う場合





## エクセルのデータ構造を扱う

プログラム内部で、エクセルのデータを作成し、
これをエクセルファイルとして書き出す方法があることを把握しておきましょう。

**data.frameとエクセルの構造は違う**


エクセルファイルの構造

- シートがある
- セルがある
- 見た目の属性

これをRのプログラムの中に作ることが出来る




```{r eval=FALSE}
# エクセルデータを作る
obj <- openxlsx::createWorkbook()

# 枚方市という名前のシートを追加
openxlsx::addWorksheet(obj, sheetName = "枚方市")

# 枚方市という名前のシートに人口データを追加
# census_dataがRのdata.frameデータ
openxlsx::writeData(obj, sheet = "枚方市", x = census_data)
```


## エクセルデータをファイルに出力

プログラムの中で作ったエクセルデータを
現実のエクセルファイルとして書き出します。


```{r eval=FALSE}
# エクセルファイルとして書き出す
openxlsx::saveWorkbook(obj, file = "hirakata.xlsx", overwrite = TRUE)
```



